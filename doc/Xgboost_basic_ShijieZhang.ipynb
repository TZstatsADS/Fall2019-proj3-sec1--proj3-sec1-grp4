{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS Project 3 Group 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Path\n",
    "\"\"\"\n",
    "DATA_PATH = \"../data/train_set\"\n",
    "IMAGE_FOLDER = os.path.join(DATA_PATH, \"images\")\n",
    "POINTS_FOLDER = os.path.join(DATA_PATH, \"points\")\n",
    "LABELS_FOLDER = DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_images():\n",
    "    \"\"\"\n",
    "    Read 2500 training images from the IMAGE_FOLDER\n",
    "    :return a 4d numpy array in form of (index, height, width, channels), channels is RGB \n",
    "    \"\"\"\n",
    "    files = [file for file in os.listdir(IMAGE_FOLDER) if file.endswith('.jpg')]\n",
    "    files.sort()\n",
    "    \n",
    "    face_images = np.zeros((len(files), 750, 1000, 3))\n",
    "    \n",
    "    for index, filename in enumerate(files):\n",
    "        face_img_arr = plt.imread(os.path.join(IMAGE_FOLDER, filename))\n",
    "        if face_img_arr.shape != (750,1000,3):\n",
    "            # resize the image\n",
    "            face_img = Image.fromarray(face_img_arr)\n",
    "            face_img = face_img.resize((1000,750))\n",
    "            face_img_arr = np.array(face_img)\n",
    "        face_images[index] = face_img_arr\n",
    "    return face_images\n",
    "\n",
    "def read_labels():\n",
    "    \"\"\"\n",
    "    Read the image labels from the label.csv file\n",
    "    :return a pandas.DataFrame with 3 columns: 'emotion_idx','emotion_cat','type'\n",
    "    \"\"\"\n",
    "    labels_df = pd.read_csv(os.path.join(LABELS_FOLDER, 'label.csv'))\n",
    "    labels_df = labels_df.loc[:,['emotion_idx','emotion_cat','type']]\n",
    "    return labels_df\n",
    "    \n",
    "\n",
    "def read_all_points():\n",
    "    \"\"\"\n",
    "    Read all face coordinates points\n",
    "    :return a tuple of shape (2500, 78, 2). Because for each of 2500 images there are 78 points associated with it\n",
    "    \"\"\"\n",
    "    files = [file for file in os.listdir(POINTS_FOLDER) if file.endswith('.mat')]\n",
    "    files.sort()\n",
    "    \n",
    "    face_points = np.zeros((len(files), 78, 2))\n",
    "    for index, filename in enumerate(files):\n",
    "        face_points_dict = loadmat(os.path.join(POINTS_FOLDER, filename))\n",
    "    \n",
    "        face_points[index] = face_points_dict.get('faceCoordinatesUnwarped',  face_points_dict.get('faceCoordinates2'))\n",
    "    return face_points\n",
    "\n",
    "def load_data(loadImage = False):\n",
    "    \"\"\"\n",
    "    Load training data from local files\n",
    "    \n",
    "    :loadImage if it's False, this function will not load original images\n",
    "    :return a tuple (images, points, labels)\n",
    "        if loadImage is False, the 'images' will None. Otherwise its a numpy array with shape (2500,750,1000,3)\n",
    "        points is a numpy array with shape (2500, 78, 2)\n",
    "        labels is a pandas.DataFrame\n",
    "    \"\"\"\n",
    "    #face_images_narr =  read_all_images() if loadImage else None\n",
    "    face_images_points = read_all_points()\n",
    "    labels = read_labels()\n",
    "    #return face_images_narr, face_images_points, labels\n",
    "    return face_images_points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass True if you want to read original images, it might take some time to do it\n",
    "#images, points, labels = load_data(True)\n",
    "points, labels = load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 78, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_idx</th>\n",
       "      <th>emotion_cat</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2497</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2498</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2499</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion_idx      emotion_cat      type\n",
       "0               1          Neutral    simple\n",
       "1               1          Neutral    simple\n",
       "2               1          Neutral    simple\n",
       "3               1          Neutral    simple\n",
       "4               1          Neutral    simple\n",
       "...           ...              ...       ...\n",
       "2495           22  Sadly disgusted  compound\n",
       "2496           22  Sadly disgusted  compound\n",
       "2497           22  Sadly disgusted  compound\n",
       "2498           22  Sadly disgusted  compound\n",
       "2499           22  Sadly disgusted  compound\n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if images:\n",
    "#    print(images.shape)\n",
    "\n",
    "print(points.shape)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "# function to calculate the distance\n",
    "def feature(input_points):\n",
    "    n = input_points.shape[0]\n",
    "    pairwise_dist_data = []\n",
    "    # return a vector\n",
    "    def pairwise_dist(vec):\n",
    "        vec = np.reshape(vec, (len(vec),1))\n",
    "        dist_matrix = pairwise_distances(vec)\n",
    "        dist_matrix = dist_matrix[np.triu_indices(dist_matrix.shape[0], k=1)]\n",
    "        return dist_matrix\n",
    "    \n",
    "    # dist is an 2 column array\n",
    "    def pairwise_dist_result(mat):\n",
    "        dist = np.apply_along_axis(func1d=pairwise_dist, axis=0, arr=mat)\n",
    "        dist_result = np.ndarray.flatten(dist,order='F').tolist()\n",
    "        return dist_result\n",
    "    \n",
    "    for i in range(n):\n",
    "        pairwise_dist_feature = pairwise_dist_result(points[i,:,:])\n",
    "        pairwise_dist_data.append(pairwise_dist_feature)\n",
    "        \n",
    "    pairwise_dist_data = pd.DataFrame(pairwise_dist_data)\n",
    "    return pairwise_dist_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature(points)\n",
    "y = labels['emotion_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Traning and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=1, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'n_estimators': [100, 200, 300, 400, 500, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model selection with cross-validation \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "para1 = {\n",
    "     'n_estimators':[100,200,300,400,500,600] \n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.1, max_depth=1)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = para1, \n",
    "                        scoring ='accuracy',\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4\n",
    "                       )\n",
    "gsearch1.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of stimators: 100\n",
      "accuracy: 0.363\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "filename = 'xgboostpara1.sav'\n",
    "pickle.dump(gsearch1, open(filename, 'wb'))\n",
    "print(\"best number of stimators: {}\".format(gsearch1.best_params_['n_estimators']))\n",
    "print(\"accuracy: {}\".format(gsearch1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=1, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para2 = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "xgb_model2 = xgb.XGBClassifier(max_depth=1, n_estimators=100)\n",
    "gsearch2 = GridSearchCV(estimator = xgb_model2, \n",
    "                        param_grid = para2, \n",
    "                        scoring ='accuracy',\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4\n",
    "                       )\n",
    "gsearch2.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.1\n",
      "accuracy: 0.363\n"
     ]
    }
   ],
   "source": [
    "filename = 'xgboostpara2.sav'\n",
    "pickle.dump(gsearch2, open(filename, 'wb'))\n",
    "print(\"best learning rate: {}\".format(gsearch2.best_params_['learning_rate']))\n",
    "print(\"accuracy: {}\".format(gsearch2.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>136.720679</td>\n",
       "      <td>38.891297</td>\n",
       "      <td>1.295959</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'learning_rate': 0.01}</td>\n",
       "      <td>0.223039</td>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.228288</td>\n",
       "      <td>0.207071</td>\n",
       "      <td>0.211340</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>460.045001</td>\n",
       "      <td>281.154844</td>\n",
       "      <td>0.805139</td>\n",
       "      <td>0.220934</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.211340</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>453.757779</td>\n",
       "      <td>210.321120</td>\n",
       "      <td>0.553683</td>\n",
       "      <td>0.124445</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>0.409314</td>\n",
       "      <td>0.417284</td>\n",
       "      <td>0.349876</td>\n",
       "      <td>0.275253</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.050936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     136.720679     38.891297         1.295959        0.642082   \n",
       "1     460.045001    281.154844         0.805139        0.220934   \n",
       "2     453.757779    210.321120         0.553683        0.124445   \n",
       "\n",
       "  param_learning_rate                   params  split0_test_score  \\\n",
       "0                0.01  {'learning_rate': 0.01}           0.223039   \n",
       "1                0.05  {'learning_rate': 0.05}           0.313725   \n",
       "2                 0.1   {'learning_rate': 0.1}           0.409314   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.229630           0.228288           0.207071           0.211340   \n",
       "1           0.355556           0.322581           0.252525           0.211340   \n",
       "2           0.417284           0.349876           0.275253           0.360825   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.220        0.009064                3  \n",
       "1            0.292        0.051705                2  \n",
       "2            0.363        0.050936                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gsearch2.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best parameters: depth=1, learning_rate=0.1, number of estimators=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "filename = 'xgboost_best.sav'\n",
    "pickle.dump(xgb_best, open(filename, 'wb'))\n",
    "print(\"accuracy: {}\".format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
