{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS Project 3 Group 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Path\n",
    "\"\"\"\n",
    "DATA_PATH = \"../data/train_set\"\n",
    "IMAGE_FOLDER = os.path.join(DATA_PATH, \"images\")\n",
    "POINTS_FOLDER = os.path.join(DATA_PATH, \"points\")\n",
    "LABELS_FOLDER = DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_images():\n",
    "    \"\"\"\n",
    "    Read 2500 training images from the IMAGE_FOLDER\n",
    "    :return a 4d numpy array in form of (index, height, width, channels), channels is RGB \n",
    "    \"\"\"\n",
    "    files = [file for file in os.listdir(IMAGE_FOLDER) if file.endswith('.jpg')]\n",
    "    files.sort()\n",
    "    \n",
    "    face_images = np.zeros((len(files), 750, 1000, 3))\n",
    "    \n",
    "    for index, filename in enumerate(files):\n",
    "        face_img_arr = plt.imread(os.path.join(IMAGE_FOLDER, filename))\n",
    "        if face_img_arr.shape != (750,1000,3):\n",
    "            # resize the image\n",
    "            face_img = Image.fromarray(face_img_arr)\n",
    "            face_img = face_img.resize((1000,750))\n",
    "            face_img_arr = np.array(face_img)\n",
    "        face_images[index] = face_img_arr\n",
    "    return face_images\n",
    "\n",
    "def read_labels():\n",
    "    \"\"\"\n",
    "    Read the image labels from the label.csv file\n",
    "    :return a pandas.DataFrame with 3 columns: 'emotion_idx','emotion_cat','type'\n",
    "    \"\"\"\n",
    "    labels_df = pd.read_csv(os.path.join(LABELS_FOLDER, 'label.csv'))\n",
    "    labels_df = labels_df.loc[:,['emotion_idx','emotion_cat','type']]\n",
    "    return labels_df\n",
    "    \n",
    "\n",
    "def read_all_points():\n",
    "    \"\"\"\n",
    "    Read all face coordinates points\n",
    "    :return a tuple of shape (2500, 78, 2). Because for each of 2500 images there are 78 points associated with it\n",
    "    \"\"\"\n",
    "    files = [file for file in os.listdir(POINTS_FOLDER) if file.endswith('.mat')]\n",
    "    files.sort()\n",
    "    \n",
    "    face_points = np.zeros((len(files), 78, 2))\n",
    "    for index, filename in enumerate(files):\n",
    "        face_points_dict = loadmat(os.path.join(POINTS_FOLDER, filename))\n",
    "    \n",
    "        face_points[index] = face_points_dict.get('faceCoordinatesUnwarped',  face_points_dict.get('faceCoordinates2'))\n",
    "    return face_points\n",
    "\n",
    "def load_data(loadImage = False):\n",
    "    \"\"\"\n",
    "    Load training data from local files\n",
    "    \n",
    "    :loadImage if it's False, this function will not load original images\n",
    "    :return a tuple (images, points, labels)\n",
    "        if loadImage is False, the 'images' will None. Otherwise its a numpy array with shape (2500,750,1000,3)\n",
    "        points is a numpy array with shape (2500, 78, 2)\n",
    "        labels is a pandas.DataFrame\n",
    "    \"\"\"\n",
    "    #face_images_narr =  read_all_images() if loadImage else None\n",
    "    face_images_points = read_all_points()\n",
    "    labels = read_labels()\n",
    "    #return face_images_narr, face_images_points, labels\n",
    "    return face_images_points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass True if you want to read original images, it might take some time to do it\n",
    "#images, points, labels = load_data(True)\n",
    "points, labels = load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 78, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_idx</th>\n",
       "      <th>emotion_cat</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2497</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2498</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2499</td>\n",
       "      <td>22</td>\n",
       "      <td>Sadly disgusted</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion_idx      emotion_cat      type\n",
       "0               1          Neutral    simple\n",
       "1               1          Neutral    simple\n",
       "2               1          Neutral    simple\n",
       "3               1          Neutral    simple\n",
       "4               1          Neutral    simple\n",
       "...           ...              ...       ...\n",
       "2495           22  Sadly disgusted  compound\n",
       "2496           22  Sadly disgusted  compound\n",
       "2497           22  Sadly disgusted  compound\n",
       "2498           22  Sadly disgusted  compound\n",
       "2499           22  Sadly disgusted  compound\n",
       "\n",
       "[2500 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if images:\n",
    "#    print(images.shape)\n",
    "\n",
    "print(points.shape)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def feature(input_points):\n",
    "    n = input_points.shape[0]\n",
    "    pairwise_dist_data = []\n",
    "    # return a vector\n",
    "    def pairwise_dist(vec):\n",
    "        vec = np.reshape(vec, (len(vec),1))\n",
    "        dist_matrix = pairwise_distances(vec)\n",
    "        dist_matrix = dist_matrix[np.triu_indices(dist_matrix.shape[0], k=1)]\n",
    "        return dist_matrix\n",
    "    \n",
    "    # dist is an 2 column array\n",
    "    def pairwise_dist_result(mat):\n",
    "        dist = np.apply_along_axis(func1d=pairwise_dist, axis=0, arr=mat)\n",
    "        dist_result = np.ndarray.flatten(dist,order='F').tolist()\n",
    "        return dist_result\n",
    "    \n",
    "    for i in range(n):\n",
    "        pairwise_dist_feature = pairwise_dist_result(points[i,:,:])\n",
    "        pairwise_dist_data.append(pairwise_dist_feature)\n",
    "        \n",
    "    pairwise_dist_data = pd.DataFrame(pairwise_dist_data)\n",
    "    return pairwise_dist_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature(points)\n",
    "y = labels['emotion_idx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Traning and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=1, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'n_estimators': [100, 200, 300, 400, 500, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model selection with cross-validation \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "para1 = {\n",
    "    'n_estimators':[100,200,300,400,500,600]  \n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(learning_rate=0.1, max_depth=1)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = para1, \n",
    "                        scoring ='accuracy',\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4\n",
    "                       )\n",
    "gsearch1.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 100}, 0.363)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4, param_grid={'max_depth': [1, 2, 3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para2 = {\n",
    "    'max_depth': [1,2,3]\n",
    "}\n",
    "xgb_model2 = xgb.XGBClassifier(learning_rate=0.1, n_estimators=100)\n",
    "gsearch2 = GridSearchCV(estimator = xgb_model2, \n",
    "                        param_grid = para2, \n",
    "                        scoring ='accuracy',\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4\n",
    "                       )\n",
    "gsearch2.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3}, 0.42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=1, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=4, param_grid={'learning_rate': [0.05, 0.1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para3 = {\n",
    "    'learning_rate': [0.05,0.1]\n",
    "}\n",
    "xgb_model3 = xgb.XGBClassifier(max_depth=3 , n_estimators=100)\n",
    "gsearch3 = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = para3, \n",
    "                        scoring ='accuracy',\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4\n",
    "                       )\n",
    "gsearch3.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.1}, 0.363)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The best parameters: depth=3, learning_rate=0.1, number of estimators=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "xgb_best1 = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100)\n",
    "xgb_best1.fit(X_train, y_train)\n",
    "pred1 = xgb_best1.predict(X_test)\n",
    "print(\"accuracy: {}\".format(accuracy_score(y_test, pred1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
